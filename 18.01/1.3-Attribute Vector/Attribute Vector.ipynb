{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于Attribute Vector\n",
    "#### 现在image caption各种模型有一些共同点，无非是改CNN，改RNN和改衔接方式，这其中可能包含几个问题:\n",
    "    CNN提取出的特征图虽然很适合图像问题，但作为输入直接衔接到翻译问题中合适吗？\n",
    "    CNN的输出要怎么加入到RNN中才能更好的使图像中的注意力信息被文本化呢？\n",
    "    多次输入效果真的不如单次好吗，如果多次输入不同呢？\n",
    "    还有最原始的问题，RNN对长句子的遗忘问题怎么解决呢？\n",
    "#### CNN提取出的特征图虽然很适合图像问题，但作为输入直接衔接到翻译问题中合适吗？。更详细的说，如何处理特征图才能更具有高层语意特征？因为我们要做的就是让图像变成一句话，所以语意特征是十分重要的。\n",
    "#### 整体流程先用attribute vector进行finetune，用detections进行预测再综合输出，得到具有较高层语意信息的RNN输入。\n",
    "    1.使提取出来的特征具有语意信息，顾名思义也就是说让特征图和单词句子挂钩，本模型使用了attribute vector。在训练集中的标注语句中提取了最常出现（至少5次）的256个词作为最具代表性的属性，这些词可以是任何词性，但是不区分时态和单复数（因为只是在标注训练集上，虽然非常可以代表训练图片的属性，缺点是词太少了，文章后面有用wordnet扩充，这个不重要这里就不说了）。\n",
    "    2.将pretrained VGG最后输出改成256D的，进行多标签任务的分类（因为一个图片可能对应好几个属性）进行微调。这里对FC层使用xavier初始化，不同的层lr策略不同，并且使用element wise logistic loss function而不是MSE。总之把这一套做完，每张图经过网络之后输出的就已经是语意属性了。\n",
    "\n",
    "#### 参考:What Value Do Explicit High Level Concept Have in Vision to Language Problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
