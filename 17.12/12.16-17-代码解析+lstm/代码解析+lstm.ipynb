{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resize.py\n",
    "    把coco数据集resize成224x224\n",
    "## prepro.py\n",
    "    _process_caption_data（） 筛选coco caption信息，得导一个字典包括 'captions' 'file_name'  'image_id' \n",
    "    _build_vocab（） 把caption信息中的单词构建词汇表\n",
    "    _build_file_names（） image路径和id的字典\n",
    "    main（） 处理数据，把annotations，captions，，file.names，image.idxs等信息保存为pkl文件\n",
    "    载入训练好的vgg19模型，初始化ndarray[n_examples, 196, 512]，把featuremap储存伪hkl文件\n",
    "## moedl.py 细节没看懂 又回过头看了看文章\n",
    "#### attendion机制中的$a_t$ 可以由前一步系统隐变量$h_t$经过若干全连接层获得。编码$e_t$用于存储前一步的信息。灰色表示模块中有需要优化的参数。\n",
    "![](http://img.blog.csdn.net/20160813194310596)\n",
    "## LSTM 隐变量生成(z→h)\n",
    "#### 这部分中采用当下流行的LSTM结构3模拟步骤之间的记忆关系。除了前文提到的内部隐状态$h_t$，还包含输入$i_t$，遗忘$f_t$，存储$c_t$，输出$o_t$，候选$g_t$共6个状态。他们都是m维变量。\n",
    "#### 输入i、输出o和遗忘f是三个“门变量”，用来控制其他状态的强度，都可以通过上一步骤的隐状态h，以及当前上下文z决定4： \n",
    "![](http://img.blog.csdn.net/20160813110405462)\n",
    "#### 存储c是LSTM的核心，由前一词的存储和当前候选g加权得到，遗忘门f控制前一词存储，输入门i控制本次候选： \n",
    "##                                             $c_t=f_t{\\bigodot}c_{t-1}+i_t{\\bigodot}g_t$\n",
    "#### 隐状态h由存储经过变化得到，强度由输出门o控制：\n",
    "## $h_t=o_t{\\bigodot}tanh(c_t)$\n",
    "#### 整个LSTM构造如下，前一步骤中的h,c输入到本步骤中。 \n",
    "![](http://img.blog.csdn.net/20160813190912583)\n",
    "\n",
    "## 详细LSTM的背景原理介绍，参考：http://www.jianshu.com/p/9dc9f41f0b29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
